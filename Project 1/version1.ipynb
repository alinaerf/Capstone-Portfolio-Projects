{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline steps\n",
    "\n",
    "1. Data Collection: Collect social media data from various sources, such as Twitter, Facebook, or Reddit. You can use APIs to retrieve data and store it in a database for further analysis.\n",
    "\n",
    "2. Data Preprocessing: Preprocess the collected data by removing irrelevant data, such as advertisements, spam, and duplicate posts. Might use natural language processing (NLP) techniques, such as tokenization, stemming, and stop-word removal, to clean and normalize the text data.\n",
    "\n",
    "3. Feature Extraction: Extract features from the preprocessed text data that can be used for machine learning. Some common features for text data include word frequency, sentiment analysis, and topic modeling.\n",
    "\n",
    "4. Labeling: Manually label a subset of the preprocessed data as \"depressed\" or \"not depressed.\" This labeled data will be used to train and validate the machine learning model. Might be already included as a variable in the dataset.\n",
    "\n",
    "5. Model Selection: Choose an appropriate machine learning model for the classification task, such as logistic regression, decision trees, or neural networks. There are also ensemble methods, such as random forests that improve the model's performance.\n",
    "\n",
    "6. Model Training: Train the chosen machine learning model using the labeled data. Use cross-validation techniques to evaluate the model's performance and tune hyperparameters to optimize the model's accuracy.\n",
    "\n",
    "7. Model Testing: Test the trained machine learning model on a separate test set to evaluate its performance on new, unseen data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection \n",
    "\n",
    "\n",
    "Potential Datasets for use:\n",
    "\n",
    "1. Sentiment140: A dataset of 1.6 million tweets labeled with sentiment (positive or negative). This dataset can be used for sentiment analysis of social media data. https://www.kaggle.com/kazanova/sentiment140\n",
    "2. CLPsych 2015 Shared Task: A dataset of social media posts from users with depression and a control group. The dataset includes annotations for depression severity and symptom severity. https://www.aclweb.org/anthology/W15-2904/\n",
    "3. Reddit Depression Dataset: A dataset of Reddit posts from users with depression and a control group. The dataset includes annotations for depression severity and suicidal ideation. https://github.com/CrisisNLP/depression-reddit-corpus\n",
    "\n",
    "\n",
    "APIs:\n",
    "\n",
    "1. Twitter API: A popular API for collecting and analyzing Twitter data. You can use the Twitter API to collect tweets that mention depression or related keywords, such as \"mental health\" or \"anxiety.\" https://developer.twitter.com/en/docs\n",
    "2. Reddit API: An API for collecting and analyzing Reddit data. You can use the Reddit API to collect posts from subreddits related to depression or mental health, such as r/depression or r/mentalhealth. https://www.reddit.com/dev/api/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
